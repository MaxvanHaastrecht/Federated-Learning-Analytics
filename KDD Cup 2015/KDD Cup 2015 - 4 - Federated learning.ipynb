{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "576723fb",
   "metadata": {},
   "source": [
    "This notebook uses the CSVs created with the OULAD - 1 - Feature engineering notebook. Make sure to run the feature engineering code before continuing with this notebook. Additionally, this notebook uses the non-standard library [PyTorch](https://pytorch.org/), which you may need to install before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de87681",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac9550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils as torch_utils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc1854",
   "metadata": {},
   "source": [
    "### Define function to split data over local clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d0901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_torch_clients(X, y, n_clients, seed = 42):\n",
    "    n_samples = len(X)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    clients_indices = []\n",
    "    random_indices = np.random.choice(n_samples, n_samples, replace = False)\n",
    "    clients_indices = np.array_split(random_indices, n_clients)\n",
    "    \n",
    "    clients = []\n",
    "    for client_indices in clients_indices:\n",
    "        X_client = X[client_indices].copy()\n",
    "        y_client = y[client_indices]\n",
    "        \n",
    "        X_torch = torch.tensor(X_client, dtype=torch.float32)\n",
    "        y_torch = torch.tensor(y_client, dtype=torch.int64)\n",
    "\n",
    "        clients.append((X_torch, y_torch))\n",
    "\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b2c29",
   "metadata": {},
   "source": [
    "### Define federated learning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a507ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.input_layer    = nn.Linear(in_dim,30)\n",
    "        self.hidden_layer1  = nn.Linear(30,10)\n",
    "        self.output_layer   = nn.Linear(10,out_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out =  self.relu(self.input_layer(x))\n",
    "        out =  self.relu(self.hidden_layer1(out))\n",
    "        out =  self.output_layer(out)\n",
    "        return out\n",
    "    \n",
    "def federated_averaging(global_model, local_models, num_clients, client_sizes):\n",
    "    dataset_size = sum(client_sizes)\n",
    "    \n",
    "    for param_global, params_local in zip(global_model.parameters(), zip(*[model.parameters() for model in local_models])):\n",
    "        weighted_sum = torch.zeros_like(param_global.data)\n",
    "        for client_params, client_size in zip(params_local, client_sizes):\n",
    "            client_weight = client_size / dataset_size\n",
    "            weighted_sum += client_weight * client_params.data\n",
    "        \n",
    "        param_global.data = weighted_sum\n",
    "        \n",
    "def train_local_model(model, dataloader, optimizer, loss_fn, epochs, device):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(data)\n",
    "            loss = loss_fn(prediction, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "def validate_local_model(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            prediction = model(data)\n",
    "            total_loss += loss_fn(prediction, target).item()\n",
    "            _, predicted_labels = torch.max(prediction, 1)\n",
    "            correct_predictions += (predicted_labels == target).sum().item()\n",
    "            total_samples += len(target)\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    return average_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3672f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_learning(clients, input_dim, output_dim, loss_fn, lr, optim_str, num_clients, num_rounds, num_epochs, batch_size):\n",
    "    # use device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") to enable gpu\n",
    "    device = torch.device(\"cpu\")\n",
    "    global_model = NeuralNetwork(input_dim, output_dim).to(device)\n",
    "    \n",
    "    client_sizes = [len(client) for client in clients]\n",
    "    for r in range(num_rounds):\n",
    "        local_models = []\n",
    "        local_optimizers = []\n",
    "        local_dataloaders = []\n",
    "        for i in range(num_clients):\n",
    "            local_model = NeuralNetwork(input_dim, output_dim).to(device)\n",
    "            local_model.load_state_dict(global_model.state_dict())\n",
    "            local_optimizer = optim.SGD(local_model.parameters(), lr=lr)\n",
    "            if optim_str == 'adam':\n",
    "                local_optimizer = optim.Adam(local_model.parameters(), lr=lr)\n",
    "            \n",
    "            X, y = clients[i]\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            local_dataloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X, y),\n",
    "                                                           batch_size=batch_size, shuffle=True)\n",
    "            train_local_model(local_model, local_dataloader, local_optimizer, loss_fn, num_epochs, device)\n",
    "            \n",
    "            local_models.append(local_model)\n",
    "            local_optimizers.append(local_optimizer)\n",
    "            local_dataloaders.append(local_dataloader)\n",
    "            \n",
    "        federated_averaging(global_model, local_models, num_clients, client_sizes)\n",
    "        if r % 10 == 0:\n",
    "            for i in range(num_clients):\n",
    "                X, y = clients[i]\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                local_dataloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X, y),\n",
    "                                                               batch_size=batch_size, shuffle=False)\n",
    "                val_loss, val_accuracy = validate_local_model(local_models[i], local_dataloader, loss_fn)\n",
    "                print(f\"Client {i+1} - Round {r + 1}/{num_rounds}, Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}\")\n",
    "            \n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e060f4d",
   "metadata": {},
   "source": [
    "### Read data and train federated learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503cdc58",
   "metadata": {},
   "source": [
    "In this code example we set the number of clients to 10. Changing N_CLIENTS to another value will easily yield the results for other local client numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6afdf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kdd_cup_2015_features.csv')\n",
    "X = df.drop(columns = ['enroll_id', 'dropout']).to_numpy()\n",
    "y = df['dropout'].to_numpy().ravel()\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "output_dim = len(np.unique(y))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "lr = 0.02\n",
    "optimizer = 'adam'\n",
    "\n",
    "N_CLIENTS = 10\n",
    "N_ROUNDS = 50\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "acc_fed, f1_fed, auc_fed = [], [], []\n",
    "for i in range(10):\n",
    "    X_main, X_holdout, y_main, y_holdout = train_test_split(X, y, test_size = 0.2, random_state = i)\n",
    "\n",
    "    torch_clients = split_into_torch_clients(X_main, y_main, N_CLIENTS)\n",
    "    global_model = federated_learning(torch_clients, input_dim, output_dim, loss_fn, lr, optimizer, N_CLIENTS, N_ROUNDS, N_EPOCHS, BATCH_SIZE)\n",
    "    \n",
    "    global_model.eval()\n",
    "    # use device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") to enable gpu\n",
    "    device = torch.device(\"cpu\")\n",
    "    with torch.no_grad():\n",
    "        predictions = global_model(torch.tensor(X_holdout, dtype=torch.float32).to(device))\n",
    "\n",
    "    _, y_pred = torch.max(predictions, dim=1)\n",
    "    y_probs = F.softmax(predictions, dim=1)[:, 1]\n",
    "\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    y_probs = y_probs.cpu().numpy()\n",
    "    \n",
    "    acc_fed.append(accuracy_score(y_holdout, y_pred))\n",
    "    f1_fed.append(f1_score(y_holdout, y_pred))\n",
    "    auc_fed.append(roc_auc_score(y_holdout, y_probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a151c44",
   "metadata": {},
   "source": [
    "### Store results as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f6a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'acc': acc_fed, 'f1': f1_fed, 'auc': auc_fed})\n",
    "\n",
    "df.to_csv('kdd_cup_2015_federated_10clients.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:swarm]",
   "language": "python",
   "name": "conda-env-swarm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
