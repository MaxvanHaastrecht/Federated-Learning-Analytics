{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9ffa8b9",
   "metadata": {},
   "source": [
    "The data used for this notebook can be downloaded from https://www.kaggle.com/datasets/sst2023/kdd-cup-2015. After unzipping the folder, you will need to place all individual CSV files in a single 'KDD Cup 2015' folder for the below code to work. The reason is that train and test data is artificially split for the Kaggle version, whereas we want to work with the full data and create random train-test splits for cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3153dac",
   "metadata": {},
   "source": [
    "### Import libraries, load train and test CSVs, and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ffeade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "df_train = pd.read_csv('KDD Cup 2015/log_train.csv')\n",
    "df_test = pd.read_csv('KDD Cup 2015/log_test.csv')\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "df_enroll_train = pd.read_csv('KDD Cup 2015/enrollment_train.csv')\n",
    "df_enroll_test = pd.read_csv('KDD Cup 2015/enrollment_test.csv')\n",
    "df_enroll = pd.concat([df_enroll_train, df_enroll_test], ignore_index=True)\n",
    "\n",
    "df_date = pd.read_csv('KDD Cup 2015/date.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fc7db6",
   "metadata": {},
   "source": [
    "### Create basic event count and date features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1340d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_dict = {}\n",
    "for enroll_id, time, source, event in zip(df['enrollment_id'], df['time'], df['source'], df['event']):\n",
    "    server = 1 if source == 'server' else 0\n",
    "    browser = 1 if source == 'browser' else 0\n",
    "    \n",
    "    nav_s = 1 if ((event == 'navigate') and server) else 0\n",
    "    nav_b = 1 if ((event == 'navigate') and browser) else 0\n",
    "    \n",
    "    acc_s = 1 if ((event == 'access') and server) else 0\n",
    "    acc_b = 1 if ((event == 'access') and browser) else 0\n",
    "    \n",
    "    prob_s = 1 if ((event == 'problem') and server) else 0\n",
    "    prob_b = 1 if ((event == 'problem') and browser) else 0\n",
    "    \n",
    "    vid_s = 1 if ((event == 'video') and server) else 0\n",
    "    vid_b = 1 if ((event == 'video') and browser) else 0\n",
    "    \n",
    "    pc_s = 1 if ((event == 'page_close') and server) else 0\n",
    "    pc_b = 1 if ((event == 'page_close') and browser) else 0\n",
    "    \n",
    "    wik_s = 1 if ((event == 'wiki') and server) else 0\n",
    "    wik_b = 1 if ((event == 'wiki') and browser) else 0\n",
    "    \n",
    "    dis_s = 1 if ((event == 'discussion') and server) else 0\n",
    "    dis_b = 1 if ((event == 'discussion') and browser) else 0\n",
    "    \n",
    "    date_time = time[0:10]\n",
    "    \n",
    "    if enroll_id in enroll_dict:\n",
    "        enroll_dict[enroll_id]['total'] += 1\n",
    "        \n",
    "        enroll_dict[enroll_id]['server'] += server\n",
    "        enroll_dict[enroll_id]['browser'] += browser\n",
    "        \n",
    "        enroll_dict[enroll_id]['nav_s'] += nav_s\n",
    "        enroll_dict[enroll_id]['nav_b'] += nav_b\n",
    "        \n",
    "        enroll_dict[enroll_id]['acc_s'] += acc_s\n",
    "        enroll_dict[enroll_id]['acc_b'] += acc_b\n",
    "        \n",
    "        enroll_dict[enroll_id]['prob_s'] += prob_s\n",
    "        enroll_dict[enroll_id]['prob_b'] += prob_b\n",
    "        \n",
    "        enroll_dict[enroll_id]['vid_s'] += vid_s\n",
    "        enroll_dict[enroll_id]['vid_b'] += vid_b\n",
    "        \n",
    "        enroll_dict[enroll_id]['pc_s'] += pc_s\n",
    "        enroll_dict[enroll_id]['pc_b'] += pc_b\n",
    "        \n",
    "        enroll_dict[enroll_id]['wik_s'] += wik_s\n",
    "        enroll_dict[enroll_id]['wik_b'] += wik_b\n",
    "        \n",
    "        enroll_dict[enroll_id]['dis_s'] += dis_s\n",
    "        enroll_dict[enroll_id]['dis_b'] += dis_b\n",
    "        \n",
    "        if date_time not in enroll_dict[enroll_id]['date_times']:\n",
    "            enroll_dict[enroll_id]['date_times'].append(date_time)\n",
    "            enroll_dict[enroll_id]['day_count'] += 1\n",
    "    else:\n",
    "        enroll_dict[enroll_id] = {'total': 1, 'server': server, 'browser': browser,\n",
    "                                  'nav_s': nav_s, 'nav_b': nav_b,\n",
    "                                  'acc_s': acc_s, 'acc_b': acc_b,\n",
    "                                  'prob_s': prob_s, 'prob_b': prob_b,\n",
    "                                  'vid_s': vid_s, 'vid_b': vid_b,\n",
    "                                  'pc_s': pc_s, 'pc_b': pc_b,\n",
    "                                  'wik_s': wik_s, 'wik_b': wik_b,\n",
    "                                  'dis_s': dis_s, 'dis_b': dis_b,\n",
    "                                  'day_count': 1, 'date_times': [date_time]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in enroll_dict.keys():\n",
    "    date_times = enroll_dict[key]['date_times']\n",
    "    date_objects = [datetime.strptime(date_time, '%Y-%m-%d') for date_time in date_times]\n",
    "    date_range = max(date_objects) - min(date_objects)\n",
    "    enroll_dict[key]['date_range'] = int(date_range.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8339427",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for e_id, stats in enroll_dict.items():\n",
    "    data.append({\n",
    "        'enroll_id': e_id,\n",
    "        'total_count': stats['total'],\n",
    "        'server_count': stats['server'],\n",
    "        'browser_count': stats['browser'],\n",
    "        'navigate_s': stats['nav_s'],\n",
    "        #'navigate_b': stats['nav_b'], all zeros\n",
    "        'access_s': stats['acc_s'],\n",
    "        'access_b': stats['acc_b'],\n",
    "        'problem_s': stats['prob_s'],\n",
    "        'problem_b': stats['prob_b'],\n",
    "        #'video_s': stats['vid_s'], all zeros\n",
    "        'video_b': stats['vid_b'],\n",
    "        #'page_close_s': stats['pc_s'], all zeros\n",
    "        'page_close_b': stats['pc_b'],\n",
    "        'wiki_s': stats['wik_s'],\n",
    "        #'wiki_b': stats['wik_b'], all zeros\n",
    "        'discussion_s': stats['dis_s'],\n",
    "        #'discussion_b': stats['dis_b'], all zeros\n",
    "        'days_active_count': stats['day_count'],\n",
    "        'date_range': stats['date_range']\n",
    "    })\n",
    "\n",
    "df_feature = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc6a232",
   "metadata": {},
   "source": [
    "### Add advanced date features (binary per day 1-30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed7a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dates = pd.merge(df_enroll, df_date, how = 'left', on = 'course_id')\n",
    "enrollment_from_dict = {}\n",
    "for e_id, from_date in zip(df_dates['enrollment_id'], df_dates['from']):\n",
    "    enrollment_from_dict[e_id] = datetime.strptime(from_date, '%Y-%m-%d')\n",
    "    \n",
    "date_arr_dict = {}\n",
    "for e_id in df_feature['enroll_id']:\n",
    "    date_arr = np.zeros(30)\n",
    "    from_date = enrollment_from_dict[e_id]\n",
    "    for date_str in enroll_dict[e_id]['date_times']:\n",
    "        date_object = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "        date_index = int((date_object - from_date).days)\n",
    "        date_arr[date_index] = 1\n",
    "        \n",
    "    date_arr_dict[e_id] = date_arr\n",
    "    \n",
    "for i in range(30):\n",
    "    feature_str = 'active_day_' + str(i+1)\n",
    "    df_feature[feature_str] = [date_arr_dict[e_id][i] for e_id in df_feature['enroll_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701d66bb",
   "metadata": {},
   "source": [
    "### Merge feature df with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a59816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truth_train = pd.read_csv('KDD Cup 2015/truth_train.csv', names=['enroll_id', 'dropout'])\n",
    "df_truth_test = pd.read_csv('KDD Cup 2015/truth_test.csv', names=['enroll_id', 'dropout'])\n",
    "df_truth = pd.concat([df_truth_train, df_truth_test], ignore_index=True)\n",
    "\n",
    "df_full = pd.merge(df_truth, df_feature, on='enroll_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fd5acf",
   "metadata": {},
   "source": [
    "### Add features signaling earlier courses completed or dropped out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c1fd0f",
   "metadata": {},
   "source": [
    "It is important to take into account that dropout information becomes available only 10 days after the end of a course, see https://www.biendata.xyz/competition/kddcup2015/ for more details. For predictions to be fair, we can only include 'historical' data from courses that have a 'to date' more than 10 days before the end of the current course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb08d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_dict = {}\n",
    "for e_id, u_id, to_date in zip(df_dates['enrollment_id'], df_dates['username'], df_dates['to']):\n",
    "    e_dict[e_id] = {'u_id': u_id, 'to_date': datetime.strptime(to_date, '%Y-%m-%d'), 'dropout': 0}\n",
    "    \n",
    "for e_id, dropout in zip(df_full['enroll_id'], df_full['dropout']):\n",
    "    e_dict[e_id]['dropout'] = dropout\n",
    "    \n",
    "u_dict = {}\n",
    "for e_id in df_full['enroll_id']:\n",
    "    u_id = e_dict[e_id]['u_id']\n",
    "    to_date = e_dict[e_id]['to_date']\n",
    "    dropout = e_dict[e_id]['dropout']\n",
    "    if u_id in u_dict:\n",
    "        u_dict[u_id]['to_dates'].append(to_date)\n",
    "        u_dict[u_id]['dropouts'].append(dropout)\n",
    "    else:\n",
    "        u_dict[u_id] = {'to_dates': [to_date], 'dropouts': [dropout]}\n",
    "        \n",
    "prev_complete = np.zeros(len(df_full))\n",
    "prev_dropout = np.zeros(len(df_full))\n",
    "for idx, e_id in enumerate(df_full['enroll_id']):\n",
    "    course_date = e_dict[e_id]['to_date']\n",
    "    \n",
    "    u_id = e_dict[e_id]['u_id']\n",
    "    all_dates = u_dict[u_id]['to_dates']\n",
    "    all_dropouts = u_dict[u_id]['dropouts']\n",
    "    \n",
    "    for earlier_date, earlier_dropout in zip(all_dates, all_dropouts):\n",
    "        if (course_date - earlier_date).days > 10:\n",
    "            if earlier_dropout == 1:\n",
    "                prev_dropout[idx] += 1\n",
    "            else:\n",
    "                prev_complete[idx] += 1\n",
    "    \n",
    "df_full['prev_complete'] = prev_complete.tolist()\n",
    "df_full['prev_dropout'] = prev_dropout.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb377c6a",
   "metadata": {},
   "source": [
    "### Store data as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f854e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.to_csv('kdd_cup_2015_features.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:swarm]",
   "language": "python",
   "name": "conda-env-swarm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
