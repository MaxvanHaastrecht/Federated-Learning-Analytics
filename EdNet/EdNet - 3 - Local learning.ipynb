{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a22ed7",
   "metadata": {},
   "source": [
    "This notebook uses the CSVs created with the EdNet - 1 - Feature engineering notebook. Make sure to run the feature engineering code before continuing with this notebook. Additionally, this notebook uses the non-standard library [XGBoost](https://xgboost.readthedocs.io/en/stable/), which you may need to install before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ddf7b3",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e051e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aadfea",
   "metadata": {},
   "source": [
    "### Define function to create final question features based on users in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff1eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_question_features(x):\n",
    "    x_new = x.sort_values('timestamp')\n",
    "    \n",
    "    q_accuracy = []\n",
    "    part_accuracy = []\n",
    "    user_excess_correct = []\n",
    "    \n",
    "    q_dict = {}\n",
    "    part_dict = {}\n",
    "    user_dict = {}\n",
    "    for part, q_id, u_id, correct in zip(x_new['part'], x_new['question_id'], x_new['user_id'], x_new['correct_response']):\n",
    "        # Calculate excess correct first to avoid contamination\n",
    "        excess_correct = 0\n",
    "        if q_id in q_dict:\n",
    "            avg_q_acc = q_dict[q_id]['n_correct']/q_dict[q_id]['n_ans']\n",
    "            excess_correct = correct - avg_q_acc\n",
    "        elif part in part_dict:\n",
    "            avg_p_acc = part_dict[part]['n_correct']/part_dict[part]['n_ans']\n",
    "            excess_correct = correct - avg_p_acc\n",
    "        else:\n",
    "            excess_correct = correct - 0.5# default\n",
    "        \n",
    "        if q_id in q_dict:\n",
    "            q_accuracy.append(q_dict[q_id]['n_correct']/q_dict[q_id]['n_ans'])\n",
    "            q_dict[q_id]['n_ans'] += 1\n",
    "            q_dict[q_id]['n_correct'] += correct\n",
    "        else:\n",
    "            q_accuracy.append(np.nan)\n",
    "            q_dict[q_id] = {'n_ans': 1, 'n_correct': correct}\n",
    "            \n",
    "        if part in part_dict:\n",
    "            part_accuracy.append(part_dict[part]['n_correct']/part_dict[part]['n_ans'])\n",
    "            part_dict[part]['n_ans'] += 1\n",
    "            part_dict[part]['n_correct'] += correct\n",
    "        else:\n",
    "            part_accuracy.append(np.nan)\n",
    "            part_dict[part] = {'n_ans': 1, 'n_correct': correct}\n",
    "            \n",
    "        if u_id in user_dict:\n",
    "            avg_excess_correct = user_dict[u_id]['sum_excess_correct'] / user_dict[u_id]['n_ans']\n",
    "            user_excess_correct.append(avg_excess_correct)\n",
    "            \n",
    "            user_dict[u_id]['n_ans'] += 1\n",
    "            user_dict[u_id]['sum_excess_correct'] += excess_correct\n",
    "        else:\n",
    "            user_excess_correct.append(np.nan)\n",
    "            user_dict[u_id] = {'n_ans': 1, 'sum_excess_correct': excess_correct}\n",
    "            \n",
    "    x_new['q_acc'] = q_accuracy\n",
    "    x_new['part_acc'] = part_accuracy\n",
    "    x_new['usr_excess_correct'] = user_excess_correct\n",
    "    \n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db86c5e",
   "metadata": {},
   "source": [
    "### Define functions to split data into train-test and into local clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c2f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_y_from_df(df):\n",
    "    uids = list(df['user_id'].unique())\n",
    "    np.random.shuffle(uids)\n",
    "    \n",
    "    n_train_uids = int(len(uids) * 0.8)\n",
    "    train_uids = uids[0:n_train_uids]\n",
    "    test_uids = uids[n_train_uids:]\n",
    "    \n",
    "    df_train = df.loc[df['user_id'].isin(train_uids)]\n",
    "    df_test = df.loc[df['user_id'].isin(test_uids)]\n",
    "    \n",
    "    X_train = df_train.drop(columns=['timestamp', 'solving_id', 'question_id', 'elapsed_time',\n",
    "                                 'user_id', 'part', 'correct_response']).to_numpy()\n",
    "    X_test = df_test.drop(columns=['timestamp', 'solving_id', 'question_id', 'elapsed_time',\n",
    "                                 'user_id', 'part', 'correct_response']).to_numpy()\n",
    "    \n",
    "    y_train = df_train['correct_response'].to_numpy().ravel()\n",
    "    y_test = df_test['correct_response'].to_numpy().ravel()\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaafde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_clients(df, n_clients, seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    uids = list(df['user_id'].unique())\n",
    "    np.random.shuffle(uids)\n",
    "    \n",
    "    clients_uids = np.array_split(uids, n_clients)\n",
    "    \n",
    "    clients = []\n",
    "    for client_uids in clients_uids:\n",
    "        df_client = create_question_features(df.loc[df['user_id'].isin(client_uids)])\n",
    "        X_train_client, X_test_client, y_train_client, y_test_client = X_y_from_df(df_client)\n",
    "        clients.append((X_train_client, X_test_client, y_train_client, y_test_client))\n",
    "\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049acf7c",
   "metadata": {},
   "source": [
    "### Define function to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff006701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(client, seed):\n",
    "    X_train, X_test, y_train, y_test = client[0], client[1], client[2], client[3]\n",
    "        \n",
    "    clf = XGBClassifier(tree_method = 'gpu_hist', random_state = seed)\n",
    "        \n",
    "    model = clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred_probs = clf.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "    return accuracy_score(y_test, y_pred), f1_score(y_test, y_pred), roc_auc_score(y_test, y_pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9b5212",
   "metadata": {},
   "source": [
    "### Read data and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baa7c6d",
   "metadata": {},
   "source": [
    "For this example we use N_CLIENTS = 10. Results for other numbers of local clients can easily be obtained by changing the value of N_CLIENTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ednet_features_10000_users.csv')\n",
    "size_dataset = len(df)\n",
    "\n",
    "N_CLIENTS = 10\n",
    "acc_arr, f1_arr, auc_arr = [], [], []\n",
    "for seed in range(10):\n",
    "    acc_arr_round, f1_arr_round, auc_arr_round = [], [], []\n",
    "    \n",
    "    clients = split_into_clients(df, N_CLIENTS, seed)\n",
    "    for client in clients:\n",
    "        client_acc, client_f1, client_auc = train_model(client, seed)\n",
    "        weight_client = (len(client[0]) + len(client[1])) / size_dataset #sum x_train and x_test\n",
    "        \n",
    "        acc_arr_round.append(client_acc * weight_client)\n",
    "        f1_arr_round.append(client_f1 * weight_client)\n",
    "        auc_arr_round.append(client_auc * weight_client)\n",
    "        \n",
    "    acc_arr.append(sum(acc_arr_round))\n",
    "    f1_arr.append(sum(f1_arr_round))\n",
    "    auc_arr.append(sum(auc_arr_round))\n",
    "    \n",
    "    print(f\"Round {seed + 1} complete. Avg acc round: {sum(acc_arr_round)}, Avg auc round: {sum(auc_arr_round)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87052cd0",
   "metadata": {},
   "source": [
    "### Store results as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81ce47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'acc': acc_arr, 'f1': f1_arr, 'auc': auc_arr})\n",
    "\n",
    "df.to_csv('ednet_local_10000users_10clients.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:swarm]",
   "language": "python",
   "name": "conda-env-swarm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
