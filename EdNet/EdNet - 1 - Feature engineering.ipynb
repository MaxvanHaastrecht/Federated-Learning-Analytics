{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e60146b7",
   "metadata": {},
   "source": [
    "The data used for this notebook can be downloaded from https://github.com/riiid/ednet. We use the EdNet-KT1 dataset. After downloading and unzipping the file folder, you can either place it directly in the directory of your code, or alter the directory references when reading the CSV files. No further preprocessing is required for the code of this notebook to work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf5278",
   "metadata": {},
   "source": [
    "### Import libraries and read accompanying question CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb39634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_q = pd.read_csv('EdNet-Contents/contents/questions.csv')\n",
    "df_q = df_q.drop(['bundle_id', 'explanation_id', 'tags', 'deployed_at'], axis = 1)\n",
    "df_q.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0b944",
   "metadata": {},
   "source": [
    "### Read individual user CSVs, construct features, and store overall CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebacdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_df(folder_path, n_users):\n",
    "    file_paths = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    file_indices = np.random.choice(len(file_paths), n_users)\n",
    "    file_paths = [file_paths[i] for i in file_indices]\n",
    "    \n",
    "    dtype_dict = {'timestamp': str, 'solving_id': int, 'question_id': str,'user_answer': str,'elapsed_time': int}\n",
    "    \n",
    "    df_list = []\n",
    "    lag_values = [i+1 for i in range(10)]\n",
    "    for idx, file_path in enumerate(file_paths):\n",
    "        if idx % 250 == 0:\n",
    "            print(f\"Now reading file {idx} of {n_users} user files.\")\n",
    "            \n",
    "        user_id = file_path.split('\\\\')[1][:-4]\n",
    "        user_df = pd.read_csv(file_path, dtype=dtype_dict)\n",
    "        user_df['user_id'] = user_id\n",
    "        user_df = user_df.merge(df_q, on='question_id', how='left')\n",
    "        # Subtract from unix timestamp to make eventual feature CSV smaller\n",
    "        user_df['timestamp'] = [int(t) - 1400000000000 for t in user_df['timestamp']]\n",
    "        # Max elapsed time set to 300, similar to Choi et al. (2020) and Shin et al. (2021)\n",
    "        user_df['elapsed_time'] = [min(300, int(t)/1000) for t in user_df['elapsed_time']]\n",
    "        user_df['correct_response'] = [1 if u == c else 0 for u, c in zip(user_df['user_answer'], user_df['correct_answer'])]\n",
    "        for lag in lag_values:\n",
    "            user_df[f'correct_response_lag_{lag}'] = user_df['correct_response'].shift(lag)\n",
    "        \n",
    "        df_list.append(user_df)\n",
    "        \n",
    "    df = pd.concat(df_list, axis = 0, ignore_index = True)\n",
    "    df['avg_correct_last_five'] = df.loc[:, ['correct_response_lag_1','correct_response_lag_2','correct_response_lag_3',\n",
    "                                            'correct_response_lag_4','correct_response_lag_5']].mean(axis = 1, skipna=False)\n",
    "    df['avg_correct_last_ten'] = df.loc[:, ['correct_response_lag_1','correct_response_lag_2','correct_response_lag_3',\n",
    "                                            'correct_response_lag_4','correct_response_lag_5','correct_response_lag_6',\n",
    "                                           'correct_response_lag_7','correct_response_lag_8','correct_response_lag_9',\n",
    "                                           'correct_response_lag_10']].mean(axis = 1, skipna=False)\n",
    "    \n",
    "    df = df.drop(['user_answer', 'correct_answer'], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f5b177",
   "metadata": {},
   "source": [
    "Note that the below code reads the data of 10,000 randomly selected users. Seeing as creating features for all users takes a prohibitively large amount of time and creates a very large feature CSV, we use the 10,000 user CSV for our local learning and federated learning experiments. For central learning we experimented with several values of N_USERS, as can be seen in our detailed results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = 'EdNet-KT1/KT1'\n",
    "N_USERS = 10000\n",
    "file_str = 'ednet_features_' + str(N_USERS) + '_users.csv'\n",
    "\n",
    "feature_df = create_feature_df(FOLDER_PATH, N_USERS)\n",
    "feature_df = feature_df.convert_dtypes()\n",
    "feature_df.to_csv(file_str, index = False)\n",
    "feature_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:swarm]",
   "language": "python",
   "name": "conda-env-swarm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
