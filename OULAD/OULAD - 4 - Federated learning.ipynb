{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38348266",
   "metadata": {},
   "source": [
    "This notebook uses the CSVs created with the OULAD - 1 - Feature engineering notebook. Make sure to run the feature engineering code before continuing with this notebook. Additionally, this notebook uses the non-standard library [PyTorch](https://pytorch.org/), which you may need to install before proceeding.\n",
    "\n",
    "We furthermore use the 'pass-fail' scenario as an example for this notebook. Results for the other OULAD scenarios can easily be obtained by altering the CSV file names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7949a378",
   "metadata": {},
   "source": [
    "### Import libraries and define functions to split data over local clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8365c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils as torch_utils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4199632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_train_test_split(df, X, y, test_size, seed):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    regions = df.columns[38:51].values\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = None, None, None, None\n",
    "    \n",
    "    for idx, region in enumerate(regions):\n",
    "        region_indices = df[df[region] == 1].index.values\n",
    "        np.random.shuffle(region_indices)\n",
    "        \n",
    "        region_size = len(region_indices)\n",
    "        train_index = int(region_size * (1 - test_size))\n",
    "        \n",
    "        train_indices = region_indices[:train_index]\n",
    "        test_indices = region_indices[train_index:]\n",
    "        \n",
    "        if idx == 0:\n",
    "            X_train = X[train_indices].copy()\n",
    "            X_test = X[test_indices].copy()\n",
    "            y_train = y[train_indices]\n",
    "            y_test = y[test_indices]\n",
    "        else:\n",
    "            X_train = np.append(X_train, X[train_indices].copy(), axis = 0)\n",
    "            X_test = np.append(X_test, X[test_indices].copy(), axis = 0)\n",
    "            y_train = np.append(y_train, y[train_indices])\n",
    "            y_test = np.append(y_test, y[test_indices])\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3d71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_torch_clients(X, y, n_clients, region_dummy, seed = 42):\n",
    "    n_samples = len(X)\n",
    "    \n",
    "    assert n_samples == len(y), 'Number of samples in X and y must be the same.'\n",
    "    assert n_clients > 0, 'Number of clients must be greater than 0.'\n",
    "    assert n_clients <= n_samples, 'Number of clients cannot be greater than number of samples.'\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    clients_indices = []\n",
    "    if region_dummy:\n",
    "        for col_idx in range(38,51):\n",
    "            column = X[:, col_idx]\n",
    "            # Due to scaling should not check for equals 1, but > 0\n",
    "            clients_indices.append(np.where(column > 0)[0])\n",
    "    else:\n",
    "        random_indices = np.random.choice(n_samples, n_samples, replace = False)\n",
    "        clients_indices = np.array_split(random_indices, n_clients)\n",
    "    \n",
    "    clients = []\n",
    "    for client_indices in clients_indices:\n",
    "        X_client = X[client_indices].copy()\n",
    "        y_client = y[client_indices]\n",
    "        \n",
    "        X_torch = torch.tensor(X_client, dtype=torch.float32)\n",
    "        y_torch = torch.tensor(y_client, dtype=torch.int64)\n",
    "\n",
    "        clients.append((X_torch, y_torch))\n",
    "\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f810c600",
   "metadata": {},
   "source": [
    "### Define federated learning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766445ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.input_layer    = nn.Linear(in_dim,30)\n",
    "        self.hidden_layer1  = nn.Linear(30,10)\n",
    "        self.output_layer   = nn.Linear(10,out_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out =  self.relu(self.input_layer(x))\n",
    "        out =  self.relu(self.hidden_layer1(out))\n",
    "        out =  self.output_layer(out)\n",
    "        return out\n",
    "    \n",
    "def federated_averaging(global_model, local_models, num_clients, client_sizes):\n",
    "    dataset_size = sum(client_sizes)\n",
    "    \n",
    "    for param_global, params_local in zip(global_model.parameters(), zip(*[model.parameters() for model in local_models])):\n",
    "        weighted_sum = torch.zeros_like(param_global.data)\n",
    "        for client_params, client_size in zip(params_local, client_sizes):\n",
    "            client_weight = client_size / dataset_size\n",
    "            weighted_sum += client_weight * client_params.data\n",
    "        \n",
    "        param_global.data = weighted_sum\n",
    "        \n",
    "def train_local_model(model, dataloader, optimizer, loss_fn, epochs, device):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(data)\n",
    "            loss = loss_fn(prediction, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "def validate_local_model(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            prediction = model(data)\n",
    "            total_loss += loss_fn(prediction, target).item()\n",
    "            _, predicted_labels = torch.max(prediction, 1)\n",
    "            correct_predictions += (predicted_labels == target).sum().item()\n",
    "            total_samples += len(target)\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    return average_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_learning(clients, input_dim, output_dim, loss_fn, lr, optim_str, num_clients, num_rounds, num_epochs, batch_size):\n",
    "    # use device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") to enable gpu\n",
    "    device = torch.device(\"cpu\")\n",
    "    global_model = NeuralNetwork(input_dim, output_dim).to(device)\n",
    "    \n",
    "    client_sizes = [len(client) for client in clients]\n",
    "    for r in range(num_rounds):\n",
    "        local_models = []\n",
    "        local_optimizers = []\n",
    "        local_dataloaders = []\n",
    "        for i in range(num_clients):\n",
    "            local_model = NeuralNetwork(input_dim, output_dim).to(device)\n",
    "            local_model.load_state_dict(global_model.state_dict())\n",
    "            local_optimizer = optim.SGD(local_model.parameters(), lr=lr)\n",
    "            if optim_str == 'adam':\n",
    "                local_optimizer = optim.Adam(local_model.parameters(), lr=lr)\n",
    "            \n",
    "            X, y = clients[i]\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            local_dataloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X, y),\n",
    "                                                           batch_size=batch_size, shuffle=True)\n",
    "            train_local_model(local_model, local_dataloader, local_optimizer, loss_fn, num_epochs, device)\n",
    "            \n",
    "            local_models.append(local_model)\n",
    "            local_optimizers.append(local_optimizer)\n",
    "            local_dataloaders.append(local_dataloader)\n",
    "            \n",
    "        federated_averaging(global_model, local_models, num_clients, client_sizes)\n",
    "        if r % 10 == 0:\n",
    "            for i in range(num_clients):\n",
    "                X, y = clients[i]\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                local_dataloader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X, y),\n",
    "                                                               batch_size=batch_size, shuffle=False)\n",
    "                val_loss, val_accuracy = validate_local_model(local_models[i], local_dataloader, loss_fn)\n",
    "                print(f\"Client {i+1} - Round {r + 1}/{num_rounds}, Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}\")\n",
    "            \n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8702237",
   "metadata": {},
   "source": [
    "### Read data and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('oulad_pass_fail_x.csv')\n",
    "X = pd.read_csv('oulad_pass_fail_x.csv').to_numpy()\n",
    "y = pd.read_csv('oulad_pass_fail_y.csv').to_numpy().ravel()\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "output_dim = len(np.unique(y))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1739f5dd",
   "metadata": {},
   "source": [
    "In this code example we set the number of clients to 10. Changing N_CLIENTS to another value will easily yield the results for other local client numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869b1793",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "lr = 0.02\n",
    "optimizer = 'adam'\n",
    "\n",
    "REGION_DUMMY = False\n",
    "N_CLIENTS = 10\n",
    "if REGION_DUMMY:\n",
    "    N_CLIENTS = 13\n",
    "    \n",
    "N_ROUNDS = 50\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "acc_fed, f1_fed = [], []\n",
    "for i in range(10):\n",
    "    X_main, X_holdout, y_main, y_holdout = None, None, None, None\n",
    "    if REGION_DUMMY:\n",
    "        X_main, X_holdout, y_main, y_holdout = region_train_test_split(df, X, y, test_size = 0.2, seed = i)\n",
    "    else:\n",
    "        X_main, X_holdout, y_main, y_holdout = train_test_split(X, y, test_size = 0.2, random_state = i)\n",
    "\n",
    "    torch_clients = split_into_torch_clients(X_main, y_main, N_CLIENTS, REGION_DUMMY)\n",
    "    global_model = federated_learning(torch_clients, input_dim, output_dim, loss_fn, lr, optimizer, N_CLIENTS, N_ROUNDS, N_EPOCHS, BATCH_SIZE)\n",
    "    \n",
    "    global_model.eval()\n",
    "    # use device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") to enable gpu\n",
    "    device = torch.device(\"cpu\")\n",
    "    with torch.no_grad():\n",
    "        predictions = global_model(torch.tensor(X_holdout, dtype=torch.float32).to(device))\n",
    "\n",
    "    _, y_pred = torch.max(predictions, dim=1)\n",
    "    y_probs = F.softmax(predictions, dim=1)\n",
    "\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "    y_probs = y_probs.cpu().numpy()\n",
    "    \n",
    "    acc_fed.append(accuracy_score(y_holdout, y_pred))\n",
    "    f1_fed.append(f1_score(y_holdout, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de481db3",
   "metadata": {},
   "source": [
    "### Store results as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7205742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'acc': acc_fed, 'f1': f1_fed})\n",
    "\n",
    "df.to_csv('oulad_pass_fail_federated_10clients.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:swarm]",
   "language": "python",
   "name": "conda-env-swarm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
